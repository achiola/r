max_iters = 100,
init_fraction = 0.2,
initializer = "kmeans++",
early_stop_iter = 10,
verbose = F)
prmb <- predict_MBatchKMeans(img.vector,
kmmb$centroids)
get.cent.mb <- kmmb$centroids
new.img <- get.cent.mb[prmb,]
dim(new.img) <- c(nrow(img.resize), ncol(img.resize), 3)
imageShow(new.img)
######## Generalizacion, con imagen de bodegon
img.name = "Seccion 07 - Tecnicas de reduccion de datos/bodegon.jpg"
img <- readImage(img.name)
imageShow(img.resize)
img <- readImage(img.name)
imageShow(img.resize)
imageShow(img)
imageShow(img)
img.vector <- apply(img , 3, as.vector)
dim(img.vector)
kmmb <- MiniBatchKmeans(img.vector,
clusters = 5,
batch_size = 20,
num_init = 5,
max_iters = 100,
init_fraction = 0.2,
initializer = "kmeans++",
early_stop_iter = 10,
verbose = F)
prmb <- predict_MBatchKMeans(img.vector,
kmmb$centroids)
get.cent.mb <- kmmb$centroids
new.img <- get.cent.mb[prmb,]
dim(new.img) <- c(nrow(img.resize), ncol(img.resize), 3)
dim(new.img) <- c(nrow(img), ncol(img), 3)
imageShow(new.img)
kmmb <- MiniBatchKmeans(img.vector,
clusters = 5,
batch_size = 20,
num_init = 5,
max_iters = 100,
init_fraction = 0.2,
initializer = "kmeans++",
early_stop_iter = 10,
verbose = F)
kmmb <- MiniBatchKmeans(img.vector,
clusters = 6,
batch_size = 20,
num_init = 5,
max_iters = 100,
init_fraction = 0.2,
initializer = "kmeans++",
early_stop_iter = 10,
verbose = F)
prmb <- predict_MBatchKMeans(img.vector,
kmmb$centroids)
get.cent.mb <- kmmb$centroids
new.img <- get.cent.mb[prmb,]
dim(new.img) <- c(nrow(img), ncol(img), 3)
imageShow(new.img)
######## imagen del muñeco
img.name = "Seccion 07 - Tecnicas de reduccion de datos/jb.jpg"
img <- readImage(img.name)
imageShow(img)
img.vector <- apply(img , 3, as.vector)
dim(img.vector)
kmmb <- MiniBatchKmeans(img.vector,
clusters = 6,
batch_size = 20,
num_init = 5,
max_iters = 100,
init_fraction = 0.2,
initializer = "kmeans++",
early_stop_iter = 10,
verbose = F)
kmmb <- MiniBatchKmeans(img.vector,
clusters = 5,
batch_size = 20,
num_init = 5,
max_iters = 100,
init_fraction = 0.2,
initializer = "kmeans++",
early_stop_iter = 10,
verbose = F)
prmb <- predict_MBatchKMeans(img.vector,
kmmb$centroids)
get.cent.mb <- kmmb$centroids
new.img <- get.cent.mb[prmb,]
dim(new.img) <- c(nrow(img), ncol(img), 3)
imageShow(new.img)
kmmb <- MiniBatchKmeans(img.vector,
clusters = 6,
batch_size = 20,
num_init = 5,
max_iters = 100,
init_fraction = 0.2,
initializer = "kmeans++",
early_stop_iter = 10,
verbose = F)
prmb <- predict_MBatchKMeans(img.vector,
kmmb$centroids)
get.cent.mb <- kmmb$centroids
new.img <- get.cent.mb[prmb,]
dim(new.img) <- c(nrow(img), ncol(img), 3)
imageShow(new.img)
protein <- read.csv("Seccion 07 - Tecnicas de reduccion de datos/protein.csv")
rownames(protein) <- protein$Country
protein$Country <- NULL
protein.scaled <- as.data.frame(scale(protein))
library(devtools)
library(factoextra)
km <- kmeans(protein.scaled, 4)
library(cluster)
library(factoextra)
km <- pam(protein.scaled, 4)
km
fviz_cluster(km)
## 95. Clustering large application (clara)
clarafit <- clara(protein.scaled, 4, samples = 5)
clarafit
fviz_cluster(clarafit)
install.packages("fpc")
install.packages("NbClust")
library(factoextra)
library(cluster)
library(fpc)
library(NbClust)
protein <- read.csv("Seccion 07 - Tecnicas de reduccion de datos/protein.csv")
rownames(protein) <- protein$Country
protein$Country <- NULL
protein.scaled <- as.data.frame(scale(protein))
nb <- NbClust(protein.scaled,
distance = "euclidean",
min.nc = 2,
max.nc = 12,
method = "ward.D2",
index = "all")
fviz_nbclust(nb) + theme_minimal()
km.res <- kmeans(protein.scaled, 3)
km.sil <- silhouette(km.res$cluster, dist(protein.scaled))
sil.sum <- summary(km.sil)
sil.sum
fviz_silhouette(km.sil)
dd <- dist(protein.scaled, method = "euclidean")
pam_stats <- cluster.stats(dd, km.res$cluster)
pam_stats
km
km_stats <- cluster.stats(dd, km.res$cluster)
km_stats
km_stats
km_stats$within.cluster.ss
km_stats$clus.avg.silwidths
km_stats$dunn
kmed <- pam(protein.scaled, 3)
kmed.stats <- cluster.stats(dd, kmed)
kmed.stats <- cluster.stats(dd, kmed$clustering)
kmed.stats$dunn
kmed_stats$within.cluster.ss
kmed.stats$within.cluster.ss
km.stats$clus.avg.silwidths
kmed.stats$clus.avg.silwidths
km.sil <- silhouette(kmed$clustering, dist(protein.scaled))
kmed.sil <- silhouette(kmed$clustering, dist(protein.scaled))
fviz_silhouette(kmed.sil)
km.sil <- silhouette(km.res$cluster, dist(protein.scaled))
fviz_cluster(km.res, data = protein.scaled)
fviz_cluster(kmed, data = protein.scaled)
fviz_cluster(km.res, data = protein.scaled)
fviz_cluster(kmed, data = protein.scaled)
fviz_cluster(km.res, data = protein.scaled)
fviz_cluster(kmed, data = protein.scaled)
res.com <- cluster.stats(dd, km.res$cluster, kmed$clustering)
res.com$corrected.rand
res.com$vi
library(fpc)
library(factoextra)
data("multishapes", package = "factuextra")
data("multishapes", package = "factoextra")
force(multishapes)
dataPoints <- multishapes[,1:2]
View(multishapes)
View(dataPoints)
plot(dataPoints)
km <- kmeans(dataPoints, 5)
fviz_cluster(km, dataPoints)
dsFit <- dbscan(dataPoints,
eps = 0.15,
MinPts = 5)
dsFit
fviz_cluster(dsFit, dataPoints)
fviz_cluster(dsFit,
dataPoints,
geom = "point")
#98. Clusterings basados en modelos
install.packages("mclust")
#98. Clusterings basados en modelos
install.packages("mclust")
library(mclust)
mclust <- Mclust(dataPoints)
plot(mclust)
summary(mclust)
bh <- read.csv("Seccion 07 - Tecnicas de reduccion de datos/BostonHousing.csv")
install.packages("corrplot")
library(corrplot)
corr <- cor(bh[,-14])
corr
corrplot(corr,
method = "color")
corrplot(corr,
method = "circle")
bh.acp <- prcomp(bh[,-14],
scale. = T)
summary(bh.acp)
plot(bh.acp)
plot(bh.acp, type = "lines")
biplot(bh.acp, col("gray", "red"))
biplot(bh.acp, c("gray", "red"))
biplot(bh.acp, col = c("gray", "red"))
head(bh.acp$x,5)
bh.acp$rotation
bh.acp$sdev
AMZN <- read.csv("Seccion 08 - Series temporales/AMZN.csv")
View(AMZN)
AMZN <- read.csv("Seccion 08 - Series temporales/AMZN.csv", stringsAsFactors = F)
View(AMZN)
APPL <- read.csv("Seccion 08 - Series temporales/AAPL.csv", stringsAsFactors = F)
FB <- read.csv("Seccion 08 - Series temporales/FB.csv", stringsAsFactors = F)
GOOG <- read.csv("Seccion 08 - Series temporales/GOOG.csv", stringsAsFactors = F)
head(AMZN)
AMZN <- AMZN[AMZN$Date>='2008-01-01',]
head(AMZN)
APPL <- APPL[APPL$Date>='2008-01-01',]
GOOG <- GOOG[GOOG$Date>='2008-01-01',]
str(APPL)
APPL$Date <- as.Date(APPL$Date)
str(APPL)
FB$Date <- as.Date(FB$Date)
GOOG$Date <- as.Date(GOOG$Date)
library(ggplot2)
ggplot(APPL,
aes(Date, close)) +
geom_line(aes(color="Apple")) +
geom_line(data = AMZN, aes(color = "Amazon")) +
geom_line(data = FB, aes(color = "Facebook")) +
geom_line(data = GOOG, aes(color = "Google")) +
labs(color = "Legend") +
scale_color_manual("", breaks = c("Apple","Amazon","Facebook","Google"),
values = c("gray", "yellow","blue", "red")) +
ggtitle("Comparaciones de cierre de stocks") +
theme(plot.title = element_text(lineheight = 0.7, face = "bold"))
ggplot(APPL, aes(Date, Close)) +
geom_line(aes(color="Apple")) +
geom_line(data = AMZN, aes(color = "Amazon")) +
geom_line(data = FB, aes(color = "Facebook")) +
geom_line(data = GOOG, aes(color = "Google")) +
labs(color = "Legend") +
scale_color_manual("", breaks = c("Apple","Amazon","Facebook","Google"),
values = c("gray", "yellow","blue", "red")) +
ggtitle("Comparaciones de cierre de stocks") +
theme(plot.title = element_text(lineheight = 0.7, face = "bold"))
View(AMZN)
APPL$Date <- as.Date(APPL$Date)
AMZN$Date <- as.Date(AMZN$Date)
FB$Date <- as.Date(FB$Date)
GOOG$Date <- as.Date(GOOG$Date)
library(ggplot2)
ggplot(APPL, aes(Date, Close)) +
geom_line(aes(color="Apple")) +
geom_line(data = AMZN, aes(color = "Amazon")) +
geom_line(data = FB, aes(color = "Facebook")) +
geom_line(data = GOOG, aes(color = "Google")) +
labs(color = "Legend") +
scale_color_manual("", breaks = c("Apple","Amazon","Facebook","Google"),
values = c("gray", "yellow","blue", "red")) +
ggtitle("Comparaciones de cierre de stocks") +
theme(plot.title = element_text(lineheight = 0.7, face = "bold"))
APPL <- read.csv("Seccion 08 - Series temporales/AAPL.csv", stringsAsFactors = F)
AMZN <- read.csv("Seccion 08 - Series temporales/AMZN.csv", stringsAsFactors = F)
FB <- read.csv("Seccion 08 - Series temporales/FB.csv", stringsAsFactors = F)
GOOG <- read.csv("Seccion 08 - Series temporales/GOOG.csv", stringsAsFactors = F)
AMZN <- AMZN[AMZN$Date>='2008-01-01',]
APPL <- APPL[APPL$Date>='2008-01-01',]
GOOG <- GOOG[GOOG$Date>='2008-01-01',]
str(APPL)
APPL$Date <- as.Date(APPL$Date)
AMZN$Date <- as.Date(AMZN$Date)
FB$Date <- as.Date(FB$Date)
GOOG$Date <- as.Date(GOOG$Date)
library(ggplot2)
ggplot(APPL, aes(Date, Close)) +
geom_line(aes(color="Apple")) +
geom_line(data = AMZN, aes(color = "Amazon")) +
geom_line(data = FB, aes(color = "Facebook")) +
geom_line(data = GOOG, aes(color = "Google")) +
labs(color = "Legend") +
scale_color_manual("", breaks = c("Apple","Amazon","Facebook","Google"),
values = c("gray", "yellow","blue", "red")) +
ggtitle("Comparaciones de cierre de stocks") +
theme(plot.title = element_text(lineheight = 0.7, face = "bold"))
### 102. Datos en tiempo real con quantmod
install.packages("quantmod")
library(quantmod)
#Cargar datos en tiempo real
getSymbols("APPL")
#Cargar datos en tiempo real
getSymbols("AAPL")
View(AAPL)
barChart(AAPL)
chartSeries(AAPL, TA = NULL)
View(AAPL)
chartSeries(AAPL[,4], TA = "addMACD()")
getSymbols("NFLX")
barChart(NFLX)
chartSeries(NFLX[,4], TA = "addMACD()")
#Hoy
Sys.Date()
#Año con dos digitos
as.Date("1/1/80", format="%m/%d/%y")
#Año con cuatro digitos
as.Date("1/1/1980", format="%m/%d/%Y")
#por defecto sume
#   yyyy-mm-dd
# o yyyy/mm/dd
as.Date("2018-01-06")
as.Date("2018-01-31")
as.Date("18-01-31")
as.Date("2018-20-31")
unaFecha <- as.Date("2018-01-31")
#fecha a numero
as.numeric(unaFecha)
as.numeric(Sys.Date())
#otros formatos
as.Date("Jan 8, 1975", format = "%b %d, %Y")
#otros formatos
as.Date("Ene 8, 1975", format = "%b %d, %Y")
#otros formatos
as.Date("Enero 8, 1975", format = "%b %d, %Y")
class(df) <- "Date"
#Casting
dt <- 2019
class(df) <- "Date"
dt
class(dt) <- "Date"
dt
#dias desde un punto dado
as.Date(10, origin = as.Date("2019-01-01"))
dt
#Componentes de las fechas
format(dt, "Y")
#Componentes de las fechas
format(dt, "%Y")
format(dt, "%b")
format(dt, "%B")
as.numeric(format(dt, "%Y"))
months(dt)
weekdays(dt)
quarters(dt)
#Componentes de las fechas
df <- as.Date("Enero 8, 1975", format = "%b %d, %Y")
format(dt, "%Y")
format(dt, "%b")
format(dt, "%B")
#Componentes de las fechas
dt <- as.Date("Enero 8, 1975", format = "%b %d, %Y")
format(dt, "%Y")
format(dt, "%b")
format(dt, "%B")
as.numeric(format(dt, "%Y"))
months(dt)
weekdays(dt)
quarters(dt)
julian(dt)
julian(dt, origin = "0000/01/01")
julian(dt, origin = "0001/01/01")
julian(dt, origin = as.Date("01/01/01"))
julian(dt, origin = as.Date("00/01/01"))
#### 104. Operaciones y secuencias de fechas
dt <-  as.Date("01/01/2001", format = "%m/%d/%Y")
df+100
dt+100
dt-100
dt2 <-  as.Date("01/02/2001", format = "%m/%d/%Y")
dt2 - dt1
dt2 - dt
dt - dt2
dt - dt
as.numeric(dt2 - dt)
dt < dt2
#secuencias
seq(dt, dt+365, "month")
seq(dt, dt+15, "day")
seq(dt, dt+365, "10 days")
seq(from =  dt, by "10 days", length.out = 10)
seq(from =  dt, by = "10 days", length.out = 10)
wmt <- read.csv("Seccion 08 - Series temporales/WMT.csv")
wmt <- read.csv("Seccion 08 - Series temporales/WMT.csv",
stringsAsFactors = F)
plot(wmt$Adj.Close, type = "l")
#diferencias entre dos dias
d <- diff(wmt$Adj.Close)
head(d)
plot(d, type = "l")
hist(d)
wmt <- read.csv("Seccion 08 - Series temporales/WMT.csv",
stringsAsFactors = F)
plot(wmt$Adj.Close, type = "l")
#diferencias entre dos dias
d <- diff(wmt$Adj.Close)
head(d)
plot(d, type = "l")
hist(d,
probability = T,)
hist(d,
probability = T,
ylim = c(0, 0.8),
main = "Walmart Stock")
hist(d,
probability = T,
ylim = c(0, 0.8),
main = "Walmart Stock",
color = "green")
hist(d,
probability = T,
ylim = c(0, 0.8),
main = "Walmart Stock",
col = "green")
lines(d,
lwd = 3)
lines(density(d),
lwd = 3)
hist(d,
probability = T,
ylim = c(0, 0.8),
main = "Walmart Stock",
col = "green")
lines(density(d),
lwd = 3)
hist(d,
probability = T,
breaks = 40,
ylim = c(0, 0.8),
main = "Walmart Stock",
col = "green")
lines(density(d),
lwd = 3)
#walmart mensual
wmt.m <- read.csv("Seccion 08 - Series temporales/WMT-monthly.csv",
stringsAsFactors = F)
wmt.m.ts <- ts(wmt.m$Adj.Close)
d <- diff(as.numeric(wmt.m.ts))
d
wmt.m.return <- d / lag(wmt.m.ts,
k = -1)
wmt.m.return <- d / lag(as.numeric(wmt.m.ts),
k = -1)
wmt.m.return
hist(wmt.m.return,
probability = T,
col = "blue")
s <- read.csv("Seccion 08 - Series temporales/ts-example.csv")
View(s)
s$ts <- ts(s)
View(s)
s <- read.csv("Seccion 08 - Series temporales/ts-example.csv")
s.ts <- ts(s)
class(s.ts)
head(s.ts)
plt(s.ts)
plot(s.ts)
s.ts.a <- ts(s,
start = 2001)
head(s.ts.a)
s.ts.a
plt(s.ts.a)
plot(s.ts.a)
#mensual
s.ts.m <- ts(s,
start = c(2001,1),
frequency = 12)
s.ts.m
plot(s.ts.m)
#quarter
s.ts.q <- ts(s,
start = 2001,
frequency = 4)
s.ts.q
plot(s.ts.q)
# Cuando empieza o termina una ts
start(s.ts.m)
end(s.ts.m)
frequency(s.ts.m)
#### con mas de una serie temporal en el mismo data set
prices <- read.csv("Seccion 08 - Series temporales/prices.csv")
head(prices)
prices.ts <- ts(prices,
start = c(1980,1),
frequency = 12)
prices.ts
plot(prices.ts)
plot(prices)
plot(prices.ts)
plot(prices.ts,
plot.type = "single",
col = 1:2)
legend("topleft",
colnames(prices.ts),
col = 1:2)
legend("topleft",
colnames(prices.ts),
col = 1:2,
lty = 1)
