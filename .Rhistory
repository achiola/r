pc2 <- apply(acp$rotation[,2] * usaarrest, 1, sum)
usaarrest$pc1 <- pc1
usaarrest$pc2 <- pc2
usaarrest[,1:4] <- NULL
install.packages("ROCR")
library(ROCR)
data1 <- read.csv("Seccion 05 - El proceso de clasificacion/roc-example-1.csv")
data2 <- read.csv("Seccion 05 - El proceso de clasificacion/roc-example-2.csv")
View(data1)
View(data2)
View(data1)
View(data2)
View(data1)
pred1 <- predict(data1$prob, data1$class)
pred1 <- prediction(data1$prob, data1$class)
View(pred1)
perf1 <- performance(prediction.obj = pred1, "tpr", "fpr")
plot(perf1)
lines(par()$usr[1,2], par()$usr[3,4])
lines(par()$usr[1:2], par()$usr[3:4])
View(perf1)
prob.cuts.1 <- data.frame(cut = perf1@alpha.values[[1]],
fpr = perf1@x.values[[1]],
tpr = perf1@y.values[[1]])
View(prob.cuts.1)
head(prob.cuts.1)
tail(prob.cuts.1)
prob.cuts.1[prob.cuts.1$tpr>=0.8]
prob.cuts.1[prob.cuts.1$tpr>=0.8,]
## Con el csv2, es casi igual, pero con etiquetas
pred2 <- prediction(data2$prob, data2$class, label.ordering = c("non-buyer","buyer"))
perf1 <- performance(pred2, "tpr", "fpr")
plot(pperf2)
plot(perf2)
plot(perf2)
perf2 <- performance(pred2, "tpr", "fpr")
plot(perf2)
lines(par()$usr[1:2], par()$usr[3:4])
install.packages("rpart")
install.packages("rpart.plot")
install.packages("caret")
library(rpart)
library(rpart.plot)
library(caret)
banknote <- read.csv("Seccion 05 - El proceso de clasificacion/banknote-authentication.csv")
View(banknote)
set.seed(2018)
training.ids <- createDataPartition(banknote$class, p=0.7, list = F)
mod <- rpart(class ~ ., data = banknote[training.ids,],
method = "class",
control = rpart.control(minsplit = 20, cp = 0.01))
mod
prp(mod,
type = 2,
extra = 104,
nn = T,
fallen.leaves = T,
faclen = 4,
varlen = 8,
shadow.col = "gray")
set.seed(2018)
training.ids <- createDataPartition(banknote$class, p=0.7, list = F)
#class ~ . = class ~ [y todas las variables del df]
#class ~ . = class ~ variance + skew + cutsosis, entropy
mod <- rpart(class ~ .,
data = banknote[training.ids,],
method = "class",
control = rpart.control(minsplit = 20, cp = 0.01))
mod
prp(mod,
type = 2,
extra = 104,
nn = T,
fallen.leaves = T,
faclen = 4,
varlen = 8,
shadow.col = "gray")
set.seed(2018)
training.ids <- createDataPartition(banknote$class, p=0.7, list = F)
#class ~ . = class ~ [y todas las variables del df]
#class ~ . = class ~ variance + skew + cutsosis, entropy
mod <- rpart(class ~ .,
data = banknote[training.ids,],
method = "class",
control = rpart.control(minsplit = 20, cp = 0.01))
mod
prp(mod,
type = 2,
extra = 104,
nn = T,
fallen.leaves = T,
faclen = 4,
varlen = 8,
shadow.col = "gray")
prp(mod,
type = 2,
extra = 104,
nn = T,
fallen.leaves = T,
faclen = 4,
varlen = 8,
roundint=FALSE,
shadow.col = "gray")
mod$cptable
0.1452381 + 0.01943149
mod.pruned <- prune(mod, mod$cptable[5, "CP"])
prp(mod.pruned,
type = 2,
extra = 104,
nn = T,
fallen.leaves = T,
faclen = 4,
varlen = 8,
roundint=FALSE,
shadow.col = "gray")
mod.pruned.2 <- prune(mod, mod$cptable[2, "CP"])
prp(mod.pruned.2,
type = 2,
extra = 104,
nn = T,
fallen.leaves = T,
faclen = 4,
varlen = 8,
roundint=FALSE,
shadow.col = "gray")
pred.pruned <- prediction(mod,
banknote[-training.ids,],
type = "class")
pred.pruned <- predict(mod,
banknote[-training.ids,],
type = "class")
table(banknote[-training.ids,]$class, pred.pruned)
table(banknote[-training.ids,]$class, pred.pruned, dnn = c("Actual","Predicho"))
pred <- predict(mod,
banknote[-training.ids,],
type = "class")
table(banknote[-training.ids,]$class, pred, dnn = c("Actual","Predicho"))
prp(mod.pruned.2,
type = 2,
extra = 104,
nn = T,
fallen.leaves = T,
faclen = 4,
varlen = 8,
roundint=FALSE,
shadow.col = "gray")
pred.pruned <- predict(mmod.pruned,
banknote[-training.ids,],
type = "class")
mod.pruned <- prune(mod, mod$cptable[5, "CP"])
prp(mod.pruned,
type = 2,
extra = 104,
nn = T,
fallen.leaves = T,
faclen = 4,
varlen = 8,
roundint=FALSE,
shadow.col = "gray")
pred.pruned <- predict(mmod.pruned,
banknote[-training.ids,],
type = "class")
pred.pruned <- predict(mod.pruned,
banknote[-training.ids,],
type = "class")
table(banknote[-training.ids,]$class, pred.pruned, dnn = c("Actual","Predicho"))
pred.pruned.2 <- predict(mod.pruned.2,
banknote[-training.ids,],
type = "class")
table(banknote[-training.ids,]$class, pred.pruned.2, dnn = c("Actual","Predicho"))
## Tipo prob
pred.pruned.prob <- predict(mod.pruned,
banknote[-training.ids,],
type = "prob")
head(pred.pruned)
head(pred.pruned.prob)
pred.prob <- prediction(pred.pruned.prob[,2], banknote[-training.ids,"class"])
View(pred.prob)
perf.prob <- performance(pred.prob, "tpr", "fpr")
plot(perf.prob)
install.packages("randomForest")
library(caret)
library(randomForest)
banknote <- read.csv("Seccion 05 - El proceso de clasificacion/banknote-authentication.csv")
View(banknote)
banknote$class <- factor(banknote$class)
View(banknote)
View(banknote)
View(banknote)
View(banknote)
View(banknote)
View(banknote)
View(banknote)
set.seed(2018)
training.ids <- createDataPartition(banknote$class, p = 0.7, list = F)
mod <- randomForest(x = banknote[training.ids, 1:4],
y = banknote[training.ids, 5],
ntree = 500,
keep.forest = T)
pred <- predict(mod, banknote[-training.ids,])
table(banknote[-training.ids, "class"], pred, dnn = c("Actual", "Predicho"))
prob <- predict(mod, banknote[-training.ids,], type = "prob")
library(ROCR)
head(prob)
pred <- predict(prob[,2],banknote[-training.ids,"class"])
pred <- prediction(prob[,2],banknote[-training.ids,"class"])
perf <- performance(pred, "tpr", "fpr")
plot(perf)
install.packages("e1071")
library(e1071)
library(caret)
bank <- read.csv("Seccion 05 - El proceso de clasificacion/banknote-authentication.csv")
bank$class <- factor(bank$class)
set.seed(2018)
training.ids <- createDataPartition(bank$class,
p = 0.7,
list = F)
mod <- svm(class ~ .,
data = bank[training.ids,])
View(training.ids)
View(mod)
View(mod)
table(bank[training.ids,"class"],
fitted(mod),
dnn = c("Actual", "Predicho"))
pred <- predict(mod, bank[-training.ids,])
table(bank[-training.ids,"class"],
pred,
dnn = c("Actual", "Predicho"))
#plot con dos variables de las cuatro..
plot(mod, data = bank[training.ids,],
skewn ~ variance)
#plot con dos variables de las cuatro..
plot(mod, data = bank[training.ids,],
skew ~ variance)
plot(mod, data = bank[-training.ids,],
skew ~ variance)
# Parametros adicionales
mod <- svm(class ~ .,
data = bank[training.ids,],
class.widhts = c("0"= 0.3, "1" = 0.7),
cost = 1)
# Parametros adicionales
tuned <- svm(class ~ .,
data = bank[training.ids,],
gamma = 10^(-6:-1),
cost = 10^(1:2)) # ajuste
summary(tuned)
# Parametros adicionales
tuned <- tune.svm(class ~ .,
data = bank[training.ids,],
gamma = 10^(-6:-1),
cost = 10^(1:2)) # ajuste
summary(tuned)
install.packages("naiveBayes")
install.packages("naivebayes")
library(naivebayes)
library(e1071)
library(caret)
ep = read.csv("Seccion 05 - El proceso de clasificacion/electronics-purchase.csv")
View(ep)
set.seed(2018)
t.ids <- createDataPartition(ep$Purchase,
p = 0.67,
list = F)
library(e1071)
library(caret)
ep = read.csv("Seccion 05 - El proceso de clasificacion/electronics-purchase.csv")
set.seed(2018)
t.ids <- createDataPartition(ep$Purchase,
p = 0.67,
list = F)
mod <- naiveBayes()
mod <- naiveBayes(Purchase ~ .,
data = ep[t.id,])
mod <- naiveBayes(ep$Purchase ~ .,
data = ep[t.id,])
mod <- naiveBayes(ep$Purchase ~ .,
data = ep[t.ids,])
t.ids <- createDataPartition(ep$Purchase,
p = 0.67,
list = F)
mod <- naiveBayes(ep$Purchase ~ .,
data = ep[t.ids,])
mod <- naiveBayes(Purchase ~ .,
data = ep[t.ids,])
mod
pred <- predict(mod, ep[-t.ids,])
table(ep[-t.ids,5], pred)
table(ep[-t.ids,]$Purchase, pred)
tab <- table(ep[-t.ids,]$Purchase,
pred,
dnn = c("Actual","Predicho"))
confusionMatrix(tab)
install.packages("class")
install.packages("class")
library(class)
library(caret)
v <- read.csv("Seccion 05 - El proceso de clasificacion/vacation-trip-classification.csv")
View(v)
#normalizamos los datos
v$Income.z <- scale(v$Income)
v$Family_size.z <- scale(v$Family_size)
set.seed(2018)
t.ids <- createDataPartition(v$Result,
p = 0.5,
list = F)
train <- v[t.ids,]
tmp <- v[-t.ids,]
v.ids <- createDataPartition(tmp$Result,
p = 0.25,
list = F)
validation <- tmp[v.ids,]
test <- tmp[-v.ids,]
v.ids <- createDataPartition(tmp$Result,
p = 0.5,
list = F)
validation <- tmp[v.ids,]
test <- tmp[-v.ids,]
# va a decidir solo el vecino mas cercano
pred1 <- knn(train[,4:5],
validation[,4:5],
train[,3],
k = 1)
tab <- table(validation$Result,
pred1,
dnn = c("Actual", "Predicho"))
summary(tab)
confusionMatrix(tab)
tab
# va a decidir solo el vecino mas cercano
pred1 <- knn(train[,4:5],
validation[,4:5],
train[,3],
k = 1)
tab1 <- table(validation$Result,
pred1,
dnn = c("Actual", "Predicho"))
tab1
# ahora con el voto de dos vecinos cercanos
pred2 <- knn(train[,4:5],
validation[,4:5],
train[,3],
k = 2)
tab2 <- table(validation$Result,
pred2,
dnn = c("Actual", "Predicho"))
tab2
# ahora con el voto de dos vecinos cercanos
pred2 <- knn(train[,4:5],
validation[,4:5],
train[,3],
k = 2)
tab2 <- table(validation$Result,
pred2,
dnn = c("Actual", "Predicho"))
tab2
# con 5
pred5 <- knn(train[,4:5],
validation[,4:5],
train[,3],
k = 5)
tab5 <- table(validation$Result,
pred5,
dnn = c("Actual", "Predicho"))
tab5
# con el conjunto de testing
pred.t <- knn(train[,4:5],
test[,4:5],
train[,3],
k = 5)
tab.t <- table(test$Result,
pred.t,
dnn = c("Actual", "Predicho"))
tab5
plot(pred.t)
#################################################################
## 67. Eligiendo el mejor número de vecinos para la decisión
#################################################################
knn.automate <- function(tr_predictors, val_predictors,
tr_target, val_target,
start_k, end_k){
for(k in start_k:end_k){
pred <- knn(tr_predictors,
val_predictors,
tr_target,
k)
tab <- table(val_target, pred, dnn = c("Actual", "Predicho"))
cat(paste("Matriz de confusion para k = ",k,"\n"))
cat("================================================\n")
cat(tab)
cat("------------------------------------------------\n")
}
}
knn.automate(train[,4:5],
validation[,4:5],
train[,3],
validation[,3],
1, 8
)
#################################################################
## 67. Eligiendo el mejor número de vecinos para la decisión
#################################################################
knn.automate <- function(tr_predictors, val_predictors,
tr_target, val_target,
start_k, end_k){
for(k in start_k:end_k){
pred <- knn(tr_predictors,
val_predictors,
tr_target,
k)
tab <- table(val_target, pred, dnn = c("Actual", "Predicho"))
cat(paste("Matriz de confusion para k = ",k,"\n"))
cat("================================================\n")
cat(tab)
cat("\n------------------------------------------------\n")
}
}
knn.automate(train[,4:5],
validation[,4:5],
train[,3],
validation[,3],
1, 8
)
#################################################################
## 67. Eligiendo el mejor número de vecinos para la decisión
#################################################################
knn.automate <- function(tr_predictors, val_predictors,
tr_target, val_target,
start_k, end_k){
for(k in start_k:end_k){
pred <- knn(tr_predictors,
val_predictors,
tr_target,
k)
tab <- table(val_target, pred, dnn = c("Actual", "Predicho"))
cat(paste("Matriz de confusion para k = ",k,"\n"))
cat("================================================\n")
print(tab)
cat("\n------------------------------------------------\n")
}
}
knn.automate(train[,4:5],
validation[,4:5],
train[,3],
validation[,3],
1, 8
)
tctrl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3)
caret_knn_fit <- train(Result ~ Family_size + Income,
data = train,
method = "knn",
trControl = trControl,
preProcess = c("center", "scale"),
tuneLength = 10)
caret_knn_fit <- train(Result ~ Family_size + Income,
data = train,
method = "knn",
trControl = tctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
caret_knn_fit
pred6 <- knn(train[,4:5],
validation[,4:5],
train[,3],
k=5,
prob = T)
pred6
install.packages("nnet")
install.packages("nnet")
install.packages("zip")
library(nnet)
library(caret)
bn <- read.csv("Seccion 05 - El proceso de clasificacion/banknote-authentication.csv")
View(bn)
bn$class <- factor(bn$class)
View(bn)
t.id <- createDataPartition(bn$class,
p = 0.7,
list = F)
mod <- nnet(class ~ .,
data = bn[t.id,],
size = 3,
maxit = 10000,
decay = 0.001,
rang = 0.05)
pred <- predict(mod,
newdata = bn[-t.id],
type = "class")
pred <- predict(mod,
newdata = bn[-t.id],
type = "class")
pred <- predict(mod,
newdata = bn[-t.id,],
type = "class")
table(bn[-t.id,]$class,
pred,
dnn = c("Actual", "Predichos"))
pred <- predict(mod,
newdata = bn[-t.id,],
type = "class",
na.action = na.omit )
pred2 <- predict(mod,
newdata = bn[-t.id,],
type = "raw")
library(ROCR)
perf <- performance(prediction(pred2, bn[-t.id,"class"]),
"tpr",
"fpr")
plot(perf)
